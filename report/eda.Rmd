---
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, cache=FALSE, warning=FALSE)
source(here::here("script/setup.R"))
```

## **Data Preparation**

In this section, we will explain the steps we did for the retrieval of the data from the US Amazon marketplace. In Addition, we will explain some of the tasks we had to apply to the text reviews in order to have the final tables. It is worth mentioning that due to the heavy computation on this section we will present the final outcomes and the examples (before and after) of the wrangling and cleaning. The code can be observed on the scrapping.RMD file.

### **Data Retrieval**

During this section, we have scrapped from the US Amazon marketplace the smartphone reviews of Apple and Samsung phones. We have decided to retrieve the reviews of the eleventh, twelfth, and the thirteenth generations of Apple. Also, we have consider the Generation S20, 2S21, and S22 for Samsung. The phones concerning each of the generation with the amount of reviews are described as follows:

* **Apple - 12,965 obs**
    + Generation 11th - **10,276 obs**
        * iPhone 11 - 5,414 obs
        * iPhone 11 Pro - 2,844 obs
        * iPhone 11 Pro Max - 2,414 obs
    + Generation 12th - **2,239 obs**
        * iPhone 12 - 975 obs
        * iPhone 12 Mini - 779 obs
        * iPhone 12 Pro - 376 obs
        * iPhone 12 Pro Max - 109 obs
    + Generation 13th - **450 obs**
        * iPhone 13 - 152 obs
        * iPhone 13 Mini - 146 obs
        * iPhone 13 Pro - 68 obs
        * iPhone 13 Pro Max - 84 obs

* **Samsung - 2,606 obs**
    + Generation S20 - **177 obs**
        * Samsung Galaxy S20 FE - 63 obs
        * Samsung Galaxy S20 Plus - 85 obs
        * Samsung Galaxy Note S20 Ultra - 29 obs
    + Generation S21 - **2,166 obs**
        * Samsung Galaxy S21 FE - 1,775 obs
        * Samsung Galaxy S21 Plus - 361 obs
        * Samsung Galaxy S21 Ultra - 30 obs
    + Generation S22 - **263 obs**
        * Samsung Galaxy S22 - 47 obs
        * Samsung Galaxy S22 Plus - 62 obs
        * Samsung Galaxy S22 Ultra - 154 obs
        
From this numbers we can say that Apple mobile phones are more popular in the US than Samsung phones, as we observe that users are more willingly to review the phones from this brand. Furthermore, the Generation 11 of Apple had the largest amount of reviews compared to the rest with the iPhone 11 at the top of the list. 


```{r}
smartphone_reviews <- read.csv(here::here("data/smartphone_reviews.csv"))

# Plot Table
smartphone_reviews[12983:12992,] %>%
  kable(caption = "Amazon US smartphones reviews - Apple and Samsung") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "300px")
```

### **Reviews Language Detection** (*Text Classification*)

After scrapping the reviews from the smartphones we noticed that some of them were written in languages different from English. For that reason, we decided to use Transformers from the Hugging Face ðŸ¤— website throughout the `pipelines()` function in order to apply tasks such as **text classification and text translations**. First, we applied the classification task from the model [eleldar/language-detection](https://huggingface.co/eleldar/language-detection), which is a fine-tuned version of [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) on the Language Identification dataset. By using this model we were able to detect the language of the reviews from our dataset.

After the application of the task `text-classification` and the model to the dataset, we created a column called *Language* to determine the language and the amount of reviews of each of them.

```{r}
apple_class <- read.csv(here::here("data/apple_class.csv"))
samsung_class <- read.csv(here::here("data/samsung_class.csv"))

# Plot Table
apple_class[1239:1244,] %>%
  kable(caption = "Appe reviews - Language Detection") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "250px")
samsung_class[51:57,] %>%
  kable(caption = "Samsung reviews - Language Detection") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "250px")
```

### **Reviews Language Translation**

For this part, we used the task for `text translations` from the model [Helsinki-NLP/opus-mt-es-en](https://huggingface.co/Helsinki-NLP/opus-mt-es-en?text=Me+llamo+Wolfgang+y+vivo+en+Berlin), which helped us to translate the reviews written in Spanish to English. We have only considered to translate this language because it was the second most representative language in our data. Languages like French, Japanese, and Hindi that we identified in our data had less than 10 observations.

For visualization purposes, we have combined both tables (input and output), to show how the translation was executed. This means that we kept only the reviews translated to English for our Analysis.

```{r}
apple_es <- read.csv(here::here("data/apple_es.csv"))
apple_es_en <- read.csv(here::here("data/apple_es_en.csv"))
samsung_es <- read.csv(here::here("data/samsung_es.csv"))
samsung_es_en <- read.csv(here::here("data/samsung_es_en.csv"))

# Apple
l <- list(a=apple_es,b=apple_es_en)
both_apple <- do.call(rbind, l)[order(sequence(sapply(l, nrow))), ]
both_apple[19:24,] %>%
  kable(caption = "Apple reviews - Language Translation") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "250px")

# Samsung
s <- list(a=samsung_es,b=samsung_es_en)
both_samsung <- do.call(rbind, s)[order(sequence(sapply(s, nrow))), ]
both_samsung[1:6,] %>%
  kable(caption = "Samsung reviews - Language Translation") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "250px")
```
<br>
After dealing with the steps explained above, we have transformed our files from having reviews with different languages to a final file with reviews in English. Thus, the number of reviews has slightly decreased, in the case of Apple from **12,965 obs to 12,712 obs**, and in the case of Samsung from **2,606 obs to 2,585**.

## **Exploratory Data Analysis**

### **Tokenization and Cleaning**

Now that we have all our text in English solely, we can start processing our dataset to transform it into a corpus. The second step is to create tokens - each tokens will be assigned a word - and to get rid of non conforming formats. Thereby, we are removing in our corpus any punctuation; symbols; numbers; separator. To have a better analysis we also decided to remove "stop words" which correspond to parasite words - in other terms, words such as "a" "the" etc... that do not add value to the analysis. Finally instead of using a steeming method, we decided to proceed with a lemmatization technique - this correspond to the usage of a lexicon dictionary that will look for the root of words, in order to get rid of unuseful repetition with minor change - teach / teaching / taught will all be reduced to the root teach. Prior to continue with graphical representation, we also compute the following information:

* DTM - Document Term matrix corresponds to the number of time a specif terms will appear
* TF-IDF -  Term Frequency Inverse Document frequency is a measure to quantify the relevance of a particular words in a document. 
* Global Frequency corresponds to the frequency of each words for each document by rank.

Below you will find two tables representing the corpus text of smartphones reviews that we are going to use. The first one is representing the corpus summary (*the text column shows the Model name with the numeration of each review across the dataset so we could identify them*) while the second one is grouped by Model type.

```{r}
Smartphone_reviews <- read.csv(here::here("data/smartphone_reviews_final.csv"))
row.name <- as.vector(Smartphone_reviews$Model)
row.name <- paste(row.name, "_", sep = "")
row.name <- paste0(row.name, 1:15297)
row.names(Smartphone_reviews) <- row.name

#Creating a corpus
Smartphone_reviews.cp <- corpus(Smartphone_reviews, text_field = "Reviews",
               meta = list(source = "Smartphone reviews"))
summary(Smartphone_reviews.cp) %>% head(10) %>% 
  kable(caption = "Corpus Summary") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "250px")

# Creating Corpus by Group Model
Smartphone_reviews.cp.group <- corpus_group(Smartphone_reviews.cp, groups = Model)
summary(Smartphone_reviews.cp.group) %>% 
  kable(caption = "Corpus Group by Model Summary") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "250px")

#Creating tokens
Smartphone_reviews.tk <- tokens(
  Smartphone_reviews.cp,
  remove_punct = TRUE,
  remove_symbols = TRUE,
  remove_numbers = TRUE,
  remove_separators = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(stop_words$word)

#lemmatization of words

Smartphone_reviews.tk <- Smartphone_reviews.tk %>%  
  tokens_replace(
  pattern = hash_lemmas$token,
  replacement = hash_lemmas$lemma)

## Compute the DTM, TF-IDF and global frequencies
Smartphone_reviews.dfm <- dfm(Smartphone_reviews.tk)
Smartphone_reviews.tfidf <- dfm_tfidf(Smartphone_reviews.dfm)  
Smartphone_reviews.freq <- textstat_frequency(Smartphone_reviews.dfm)

## Compute the DTM, TF-IDF and global frequencies per group
Smartphone_reviews.dfm.group <- dfm_group(Smartphone_reviews.dfm, groups = Model)
Smartphone_reviews.tfidf.group <- dfm_tfidf(Smartphone_reviews.dfm.group)  
Smartphone_reviews.freq.group <- textstat_frequency(Smartphone_reviews.dfm.group)

```
<br>

#### **Plotting frequency**

Observing the frequency plot we can analyse that the most common word used was "phone" followed by "battery" and "screen". While phone comes without surprise as  we got our information from phones reviews on amazon, an interesting point came from the two most used words afterwards. Indeed, we might affirm, with this graphs that the hottest topic for a consumers is the battery life of a new phone and the quality of its screen rather than the software behind it nor the features added. 

```{r}
Smartphone_reviews.freq %>% 
  top_n(20, frequency) %>%
  ggplot(aes(
    x = reorder(feature, frequency),
    y = frequency, fill=feature)) + 
  geom_bar(stat = "identity") + 
  coord_flip() +
  xlab("Frequency") + 
  ylab("Term") +
  theme(legend.position="none")
```

**Models Frequency based on DFM - Ungrouped**

This graph focused on the frequency of the 5 more common words used for each of the documents available. An interesting thing, to note is that in our dataset more than 80% of the reviews came from apple buyers. Nonetheless, in this sample showed, it appears that most words used are related to android instead of IOS. Another interesting fact to note is that the most common word used all through out the corpus are - samsung, s9, s20, phone, onplus, entry, device, camera, apple.

```{r, fig.height=7}
Smartphone_reviews.dfm %>% 
  tidy() %>% 
  top_n(10, count) %>% 
  ggplot(aes(x = term, y = count, fill=term)) + 
  geom_bar(stat = "Identity") + 
  coord_flip() +
  theme(axis.text.y = element_text(size = 8),
        axis.ticks.y = element_blank())  + 
  facet_wrap(~document, ncol = 2) +
  xlab("Count") + 
  ylab("Term") +
  scale_fill_discrete(name = "Term")
```

**Models Frequency based on DFM - Grouped by Model**

Unsurprisingly we observed that the Models chosen by the DFM on the top part of the chart are the ones with the highest amount of Tokens. The common ground across the models is the impression that customers talked about the phone and in some cases about the seller. As an example, we discover that on the iPhone 11 some of the reviews were about the conditions of the smartphones as they were refurbished and users were praising or complaining about what they had received. Some of the top 5 terms that were used were - screen, scratch, phone, iphone, buy, battery - this concur with the previous discovery. Furthermore, the usage of the term **phone** is used among all models while **scratch** is mostly used in iPhone 11. 

**Models Frequency based on TF-IDF - Grouped by Model**

On the bottom part of the chart, we have the same models as seen on top, but the difference lie on the relevance on the token used in regard to the review. This implies that the terms shown explain the main context of the review. Thereby, iPhone 11 model was explained by **scratch** as the main theme, meanwhile, for Samsung Galaxy S21 FE is all about comparison  with the previous model (Samsung Galaxy S20 FE). Also we detected that the iPhone 11 Pro's reviews followed the same pattern as the iPhone 11, but with the main difference being the terms **aesthetic and generic**.


```{r, fig.height=6}
# Plot per document grouped 
p1 <- Smartphone_reviews.dfm.group %>% 
  tidy() %>% 
  top_n(10, count) %>% 
  ggplot(aes(x = term, y = count, fill=term)) + 
  geom_bar(stat = "Identity") + 
  coord_flip() +
  labs(title = "Models Frequency based on DFM - Grouped by Model") +
  theme(
        axis.text.y = element_text(size = 8),
        axis.ticks.y = element_blank())  + 
  facet_wrap(~document, ncol = 2) 

p2 <- Smartphone_reviews.tfidf.group%>% 
  tidy() %>% 
  top_n(10, count) %>% 
  ggplot(aes(x = term, y = count, fill=term, palette= "heat")) + 
  geom_bar(stat = "Identity") + 
  coord_flip() +
  labs(title = "Models Frequency based on TF-IDF - Grouped by Model") +
  theme(
        axis.text.y = element_text(size = 8),
        axis.ticks.y = element_blank())  + 
  facet_wrap(~document, ncol = 2) +
  scale_fill_discrete(name = "Term") +
  scale_fill_brewer(palette = "Paired")

p1/p2

```

#### **Plotting maximum TF_IDF per document**

Due to the large amount of reviews, we decided to create a visualization of the max TF-IDF for each documents instead of showing each one of them. Thereby, the following representation tell us that each of those words have at least a large TF-IDF in on document. Analyzing the output, entry seems to be the word having the most relevance followed then by "oneplus" "s9" "s20". While the words ranked 2 to 4 are all specif to model, it turns out that "entry" is what matter most for a consumers. Entry in the context of purchase might corresponds to leader price. 

```{r}
#Plotting maximum TF_IDF per Document
Smartphone_reviews.tfidf %>% 
  tidy() %>%
  group_by(term) %>%
  summarize(count = max(count)) %>%
  ungroup() %>% 
  arrange(desc(count)) %>%
  top_n(20, count) %>%
  ggplot(aes(x=reorder(term, count),
             y = count)) + 
  geom_bar(stat = "identity") + 
  coord_flip() +
  xlab("Max TF-IDF") + 
  ylab("Term")
```

We applied the same procedure as the chart above, but in this case we chose to group the documents by Model so we could identify which terms have the largest TF-IDF on each smartphone. From the chart, we can interpret the following:

* The Mini versions of the iPhone models 12 and 13 the largest weighted frequency term is **mini**.
* For smartphones models like iPhone 11, iPhone 11 Pro, iPhone 11 Pro Max and iPhone 12, and iPhone 12 Pro, we can say that the terms **iphone and scratch** are very relevant words used on users reviews.
* For the last row, we can identify that most important words are related to the model of the smartphone, for example: Samsung Galaxy S21 Plus has the word "S21" on the top of the terms, same for Samsung Galaxy S22, Samsung Galaxy S22 Plus, Samsung Galaxy 20, and Samsung Galaxy 22 Ultra. One interesting point to mention is that Samsung Galaxy S21 FE has for the second most significant term the word S20. Meaning that that most users were comparing the new generation S21 to the old one S20.
* As for the models iPhone 13 Pro, iPhone 13 Pro Max, Samsung Galaxy Note 20 Ultra, and Samsung Galaxy S20 FE, they have a term which is more specific to each of them (*arise, max,ejection, and sm-g780*).  

```{r, fig.width=10, fig.height=10}
# Plotting maximum TF_IDF per document grouped

Smartphone_reviews.tfidf.group %>% 
  tidy() %>%
  group_by(document) %>%
  slice_max(count, n = 6) %>%
  ungroup() %>%
  ggplot(aes(count, reorder_within(term, count, document), fill = document)) +
  geom_col(show.legend = FALSE) + scale_y_reordered() +
  facet_wrap(~document, ncol = 4, scales = "free") +
  labs(x = "Max TF-IDF", y = NULL)
```


#### **Document log frequency**

While this log frequency representation is quite messy due to the amount of document used, we can still distinguish the tokens found during the frequency plot representation. Indeed - phone, battery, screen - are the most common words used and are present in nearly every document. On the other hand, we observe - entry - having a lesser document frequency, meaning that it appears less often, while still maintaining a decent log-frequency implying that it is specif to some documents only. 

```{r}
Smartphone_reviews.freq %>% 
  ggplot(aes(x = log10(docfreq),
             y = log10(frequency))) + 
  geom_text(aes(label=feature),
            position=position_jitter(),
            size = 3) + 
  xlab("Document log-frequency") + 
  ylab("log-frequency")
```


#### **Words Cloud**

Another representation of the Document frequency matrix is through a word cloud, where the the most relevant words has the biggest size. From this cloud, we can identify - phone, battery, screen, iPhone, scratch, condition - as the most used words.

```{r}
textplot_wordcloud(Smartphone_reviews.dfm)
```


#### **Lexical diversity**

We now want to take a glance a the diversity of words used. This is an interesting approach as it allows us to see if reviews are rich in vocabulary or if instead, they are repetitive. Due to the number of documents, we will only show a sample. A limitation of this representation is that the lexical diversity is dependent on the size of the sentence, in this case the reviews. Nonetheless it give us insight on how diverse the reviewers is in term of words used. The highest the TTR the more diverse the lexical is. 

For instance, what we can see on the chart is that in the model Samsung Galaxy 21 Ultra we note a higher lexical diversity than the rest of the models. If we look at it with a bigger lens, the top models with the highest lexical assortment are from the brand Samsung followed only by Pro version of Apple thirteenth generation. We find that model with the highest number of tokens is iPhone 11, but it is the one with the lowest lexical distinction.

```{r}
# Lexical diversity per document(Model grouped)
Smartphone_reviews.dfm.group %>% textstat_lexdiv() %>% 
  ggplot(aes(reorder(document, -TTR),
             TTR)) + 
  geom_bar(stat="identity") +
  xlab("Model") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.2, hjust=0.95),
        strip.text = element_text(size=7)) 

```

#### **Keyness** {.tabset}

To continue with our analysis we decided to applied a Chi-square test of independence between Apple's and Samsung's reviews. The purpose of this test is to compare term from a set of document to another, in this case we want to put in perspective terms used from one consumers base to an others. We create a plot with the keyness results, we also added for reference two tables containing the 10 first values from the Chi-square test for both Samsung and Apple as target. 

From the graph, we can see that both reviews will have as most common words used their respective brand. The main difference lays in the following exclusive words used. It seems that for  Samsung most of the term are related to other models (Apple as reference). Meanwhile, if Apple becomes the target (Samsung as reference), it appears that the most common terms used are - condition, and scratches.

Our intuition behind this pattern, could be due for Samsung to the amount of product they proposed, thus reviewers have a larger set of comparison when reviewing:

* Galaxy-S
* Galaxy-A
* Galaxy-Z
* Galaxy-Foldables
* Galaxy-Notes

as for Apple:

* Iphone 
* Iphone mini
* Iphone Pro
* Iphone SE

##### Key terms of Apple vs Samsung {.active}
```{r, fig.width=10}
## Key terms of Apple vs Samsung
## Take a sub-corpus and clean it
Smartphone_reviews.tk2 <- tokens(corpus_subset(
  Smartphone_reviews.cp,
  Brand %in% c("Apple", "Samsung")),
  remove_punct = TRUE,
  remove_symbols = TRUE,
  remove_numbers = TRUE) %>% 
  tokens_tolower()  %>%  
  tokens_remove(pattern = stop_words$word)

## Compute and show key terms
Smartphone_reviews.tk2 %>% 
  dfm() %>% 
  dfm_group(Brand) %>% 
  textstat_keyness(target = "Samsung") %>%
  textplot_keyness()

```

##### Chi-square table - Samsung as Target 

```{r}
## table
Smartphone_reviews.tk2 %>% 
  dfm() %>% 
  dfm_group(Brand) %>% 
  textstat_keyness(target = "Samsung") %>%
  head(10) %>% 
  kable(caption = "Samsung as Target") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "250px")
```

##### Chi-square table - Apple as Target 

```{r}
Smartphone_reviews.tk2 %>% 
  dfm() %>% 
  dfm_group(Brand) %>% 
  textstat_keyness(target = "Apple") %>%
  head(10) %>% 
  kable(caption = "Apple as Target") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "250px")
```

## {-}


#### **Link between words**

To get an idea of the relationship between words - what are the most common combination - we decided to present a visual representation of those links. From the following graph we interpret that the majority of the most common words are linked directly with the term "phone" - this of course makes sense as we are working on phones reviews. It can be noted however that on the outer reach of this plot terms such as - perfect, excellent, recommend, happy - are reviews that mostly appears only with one token. This could explain the reason why on this graph these terms do not appear with links to others tokens. 

```{r}
## Represent some links between terms
smartphone_reviews.co <- fcm(Smartphone_reviews.tk, 
                 context = "document",
                 tri = FALSE)
index <- Smartphone_reviews.freq %>% 
  filter(frequency > 800) %>% 
  data.frame() %>% 
  select(feature)
smartphone_reviews.co <- smartphone_reviews.co[index$feature, index$feature]
smartphone_reviews.co[smartphone_reviews.co <= 2000] <- 0
smartphone_reviews.co[smartphone_reviews.co > 2000] <- 1
network <- graph_from_adjacency_matrix(
  smartphone_reviews.co,
  mode = "undirected",
  diag = FALSE)
plot(network,
     layout = layout_with_kk)

```


