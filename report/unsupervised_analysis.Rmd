---
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, cache=FALSE, warning=FALSE)
source(here::here("script/setup.R"))
```

# **Unsupervised Learning**

## **Similarities**

For the unsupervised learning analysis, we will be analyzing the similarities between each of the models and the similarities between words that are present in the reviews. Out of the three distance measurements, we will be using Euclidean Distance as our distance/similarity measurement for this project as it compares the shortest distance among objects.

```{r}
smartphone.euc <- textstat_dist(
  Smartphone_reviews.tfidf.group,
  method = "euclidean",
  margin = "documents")
```

To read the euclidean distance from the matrix is quite complex since there are several models. Therefore, to highlight similarities in an easier way, we create a heatmap representation of the similarities between the reviews.

Looking at the heatmap of the grouped reviews below, we can conclude the following points:

-   iPhone 11 is not similar to any other phone. The closest one to it is the iPhone 11 Pro where the euclidean distance is around 0.5.
-   Samsung Galaxy S21 FE is not similar to any other phone
-   Samsung Galaxy S22 and S22 Plus are the ones that are similar to almost all the remaining phone models, excpet of course to iPhone 11 and 11 Pro.

Further, we have studied the graph that plots the euclidean distances based on the thickness of the line connecting them. The thicker the line, the more dissimilar or further the models are. Therefore, as we have seen in the heat map earlier and based on the thickness of the lines we see, this graphs also confirms our previous findings that Samsung Galaxy S21 FE and iPhone 11 are the most dissimilar models from all the other models.

```{r, fig.align='center'}
## Euclidean

# Since we are taking the Euclidean distance, we will first need to transform the distances to similarities bounded between 0-1. 
smartphone.euc.matrix <- melt(as.matrix(smartphone.euc))
max_dist <- max(smartphone.euc.matrix$value) # to get the maximum distance
smartphone.euc.matrix$value.std <- (max_dist - smartphone.euc.matrix$value)/max_dist 

#Heatmap
ggplotly(ggplot(
  data = smartphone.euc.matrix,
  mapping = aes(x = Var1, 
                y = Var2,
                fill = value.std)) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white", 
    midpoint = 0.5,
    limit = c(0, 1),
    name = "Similarity") +
  geom_tile() + xlab("") + ylab("") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.2, hjust=0.95),
        strip.text = element_text(size=7)))


library(qgraph)

qgraph(as.matrix(smartphone.euc), shape= "circle", posCol= "darkgreen", negCol="darkred", layout="groups", vsize=10)

```

### **Clustering of Documents**

Moving on to the Clustering of Documents, we have created some dendrograms to show which models are similar to each other and at which stage are they clustered together. We can see here that one of the first clusters that was made was between iPhone 13 Pro and Samsung Galaxy 21 Ultra. Further, as you can see, we can choose to have four (4) clusters. Comparing the results of the dendrogram to our previous results, we can also confirm the dissimilarity level between the models and iPhone 11 and Samsung Galaxy S21 FE as they were added to the cluster in the last two iterations.

For the clustering below, we have chosen the complete linkage method as it provides almost the same results as average linkage method and shows clearly distic=nct clusters.

```{r}
smartphone.hc <- hclust(as.dist(smartphone.euc), method = "complete")
plot(smartphone.hc)
```

```{r, include=FALSE}

smartphone.clust <- cutree(smartphone.hc, k = 4)
smartphone.clust


smartphone.km <- kmeans(Smartphone_reviews.tfidf.group, centers = 4)
smartphone.km$cluster
```

Analyzing the results of the K-means on 4 clusters, we can see that we have the ratio of Between Sum of Squares to the Total Sum of Squares equal to around 90% making the ratio of Within Sum of Squares equal to 10%. These results look promising as we would like to increase the Between Sum of Squares and decrease the Within Sum of Squares <br>

#### Extract the ten words that are the most used. {.tabset}

We have then created the 4 clusters and have chosen to extract the 10 words that are more often used in each cluster to get an insight on what each cluster talks about.

##### Clusters based on TF-IDF - Grouped by Model {.active}
```{r}
data.frame(
  Clust.1 = names(sort(apply(Smartphone_reviews.tfidf.group[smartphone.clust==1, ], 2, sum), decreasing = TRUE)[1:10]),
  Clust.2 = names(sort(apply(Smartphone_reviews.tfidf.group[smartphone.clust==2, ], 2, sum), decreasing = TRUE)[1:10]),
  Clust.3 = names(sort(apply(Smartphone_reviews.tfidf.group[smartphone.clust==3, ], 2, sum), decreasing = TRUE)[1:10]), 
  Clust.4 = names(sort(apply(Smartphone_reviews.tfidf.group[smartphone.clust==4, ], 2, sum), decreasing = TRUE)[1:10])
) %>% 
  kable(caption = "Clusters based on TF-IDF - Grouped by Model") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "250px")
```

##### K-means Clusters based on TF-IDF - Grouped by Model

```{r}
data.frame(
  Clust.1 = names(sort(apply(Smartphone_reviews.tfidf.group[smartphone.km$cluster==1,], 2, sum), decreasing = TRUE)[1:10]),
  Clust.2 = names(sort(apply(Smartphone_reviews.tfidf.group[smartphone.km$cluster==2,], 2, sum), decreasing = TRUE)[1:10]),
  Clust.3 = names(sort(apply(Smartphone_reviews.tfidf.group[smartphone.km$cluster==3,], 2, sum), decreasing = TRUE)[1:10]),
  Clust.4 = names(sort(apply(Smartphone_reviews.tfidf.group[smartphone.km$cluster==4,], 2, sum), decreasing = TRUE)[1:10]) 
) %>% 
  kable(caption = "K-mean Clusters based on TF-IDF - Grouped by Model") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% scroll_box(width = "100%", height = "250px")
```
## {-}


### **Similarities between Words**

Then we do the similarities by words. We also create a heat map to show the similarities between words. Surprisingly, the heat map below does not show similarities between any of the words. The closest similarity between two words was between "life" and "saver" with around 0.55 cosine angle which makes sense since those two (2) words sometimes come together.

Then we do the similarities by words. We also create a heat map to show the similarities between words. The heat map below shows similarities between all of the words used in the reviews. However, the word "samsung" has the most dissimilarities with the others compared to the other words. Looking into details, to the similarities of the word "samsung", we can see that the most similar words to it are "camera" and "fast". Therefore, we can say that, between all the features, what most people commented about in the samsung phone is it's speed and it's camera.

<br>

On the other hand, if we look at the similarity matrix for the iPhone, we can see that is is similar to almost all the features that were mentioned which means that the consumers have mentioned those features evenly in their reviews. However, it is least similar to the words, "camera", "fast", and "card". Which means that these words were not mentioned a lot in the iPhone reviews with respect to other words.

```{r, fig.align='center'}
smartphone.feat <- textstat_frequency(Smartphone_reviews.dfm.group) %>% 
  filter(rank <= 50) # words with frequency rank less than 40 (it should correspond to the 50 most frequent words 
smartphone.feat$feature

smartphone.word.cos <- textstat_simil(
  Smartphone_reviews.dfm.group[, smartphone.feat$feature],
  method = "cosine",
  margin = "feature")
smartphone.word.cos.matrix <- melt(as.matrix(smartphone.word.cos)) # Convert the object to matrix then to data frame 

ggplotly(ggplot(data = smartphone.word.cos.matrix, aes(x=Var1, y=Var2, fill=value)) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white",
    midpoint = 0.5,
    limit = c(0, 1),
    name = "Cosine") +
  geom_tile() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
    axis.text.y = element_text(size = 8)) +
  xlab("") + 
  ylab(""))
```

### **Clustering Words**

The below dendrogram shows how each word is clustered and with the other words. we can c;early see four (4) clusters. As seen previously in the heatmap, the word samsung will be clustered in a cluster by itself as it is the most dissimilar word from the others.

```{r}
smartphone.word.hc <- hclust(as.dist(1 - smartphone.word.cos), method = "complete")
plot(smartphone.word.hc)
```

### **Co-occurence**

Cooccurence describes how words occur together which in turn captures the different relationships between words. From there we can see thatthe most coocuuring words together are the words "phone" and "battery". We can also clearly see that from the dendrogram.

```{r, fig.align='center'}

#### TO CHECK IF WE SHOULD USE THE GROUPED ONE ####

Smartphone_reviews.tk.group <- tokens(
  Smartphone_reviews.cp.group,
  remove_punct = TRUE,
  remove_symbols = TRUE,
  remove_numbers = TRUE,
  remove_separators = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(stop_words$word)


smartphone.fcm <- fcm(Smartphone_reviews.tk.group, 
                 window = 3, 
                 tri = FALSE)
smartphone.fcm <- (smartphone.fcm + t(smartphone.fcm))/2 
```

```{r}
# heat map of the most frequent features

smartphone.fcm.mat <- melt(
  as.matrix(
    smartphone.fcm[smartphone.feat$feature, smartphone.feat$feature]),
  varnames = c("Var1", "Var2")) 
ggplotly(ggplot(data = smartphone.fcm.mat, 
       mapping = aes(x = Var1, y = Var2, fill = value)) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white",
    midpoint = 140,
    limit = c(0, 280),
    name = "Co-occurrence") +
  geom_tile() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 5),
        axis.text.y = element_text(size = 5)) +
  xlab("") +
  ylab(""))

```

```{r}
# Produce clustering analysis. The co-occurrences are turned into dissimilarities before

smartphone.inv_occ <- 
  280 - as.matrix(
    smartphone.fcm[smartphone.feat$feature, smartphone.feat$feature]) ## 280 is the max co-occurrence here

smartphone.occ.hc <- hclust(as.dist(smartphone.inv_occ), method = "complete")
plot(smartphone.occ.hc)
```

## **Topic Modeling**

We decided to use Topic modeling to discover the abstract "topics" that occur in a collection of documents, in this case the grouped corpus of smartphones Models (*Wikipedia,2022*). Topic Modeling will help us to identify the context of the documents by detecting similar words patterns inside them, and by clustering those group of words together.

### **LSA on Term Frequencies (DFM)** {.tabset}

Latent Semantic Analysis, or LSA, is one of the techniques that we will use for topic modeling. LSA is a reduction technique that decomposes the DTM into 3 matrices ($M = ð‘ˆÎ£ð‘‰^{ð‘¡}$), where $Î£$ represents the strength of the topic, $ð‘ˆ$ the links among the document and every topic, and $ð‘‰^{t}$ the links between the terms and each topic.

First, we started by plotting the first dimension to corroborate if it is associated with the document length, as it is known that this happens in LSA dim1. Looking at the result observed on the tab called Dimension 1, we can confirm that it is the case, as we detect that Dimension 1 is negatively correlated. Furthermore, we can see that the **iPhone 11** is in the bottom-right hand side of the chart being the one with the highest amount of tokens, while **Samsung Galaxy 21 Ultra** is located on the top-left hand side with the lowest amount.

On the second tab "Topics 2 and 3", we interpret which words are the top 5 associated to topics 2 and 3, and the top5 negatively associated to those topics. In the table for Topic 2 we detect that the words "scratch", "iphone", "condition", "battery" and "product" are the ones associated to this topic, while "5g", "s20", "camera", "phone" and "samsung" are negatively linked. We can say that Topic 2 can be identified on models from the brand Apple. On the other hand, in the table for Topic 3 we discover that the main words related to this topic were - pro, samsung, arrive, battery and camera - and the negative associated were brand, buy, iphone, unlock, and phone. This Topic may be seen on model reviews from the brand Samsung and some of the Pro models from Apple.

For a visual representation of the words stated previously on topic 2 and topic 3, we plot the dimensions that correspond to those topics (*Dim 2 & 3*) in a biplot chart. In the tab "Biplot of Dim 2 and 3" we can confirm the points mentioned before, as we note the same words associated with Dim 2 (*Topic 2*) and negatively associated, same case for Dim 3 (*Topic 3*). Samsung Galaxy S21 FE, iPhone 11 Pro Max and iPhone 11 Pro are associated with Topic 3, while iPhone 11 is unconnected to this topic. For Topic 2 we can determine that iPhone 11 Pro, iPhone 11 Pro Max, iPhone 11, and iPhone 12 are related to it.

#### Dimension 1 {.active}

```{r, fig.width=8}
# Build LSA object
Smartphone_reviews.lsa <- textmodel_lsa(
  x = Smartphone_reviews.dfm.group,
  nd = 5) 

models.freq <- ntoken(Smartphone_reviews.tk.group)
lsa.dim1 <- data.frame(models.freq,
           dim1 = Smartphone_reviews.lsa$docs[, 1])
lsa.dim1$names <- rownames(lsa.dim1)
lsa.dim1 <- data.frame(lsa.dim1)

# Plot chart
plot_ly(data = lsa.dim1, x = ~models.freq, y = ~dim1, color = ~names,
        colors = "Set1", text = ~paste("Model: ", names)) %>% 
  layout(xaxis = list(title = 'Number of Tokens'), 
         yaxis = list(title = 'LSA Dim 1'),
         legend = list(title=list(text='<b> Smartphone Models </b>')))
```

#### Topics 2 and 3

```{r}
# Define the number of terms to filter
n.terms <- 5

# For Dimension 2
w.order <- sort(Smartphone_reviews.lsa$features[, 2], decreasing = TRUE)
w.top2 <- c(w.order[1:n.terms], rev(rev(w.order)[1:n.terms]))


# For Dimension 3
w.order <- sort(Smartphone_reviews.lsa$features[,3], decreasing = TRUE)
w.top3 <- c(w.order[1:n.terms], rev(rev(w.order)[1:n.terms]))

w.top2 %>% 
  kable(caption = "Topic 2") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) 
w.top3 %>% 
  kable(caption = "Topic 3") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) 
```

#### Biplot of Dim 2 and 3

```{r}
w.subset <- Smartphone_reviews.lsa$features[
    c(unique(c(names(w.top2), names(w.top3)))), 2:3]

biplot(
  y = Smartphone_reviews.lsa$docs[, 2:3],
  x = w.subset,
  col = c("black","red"),
  cex = c(0.8, 0.8),
  xlab = "Dim 2",
  ylab = "Dim 3")

```

##  {.unnumbered}

### **LSA on Term Frequencies (TF-IDF)**

Now, we apply the same approach as above, but in this case we will use the TF-IDF matrix. As we have already explain, the TF-IDF quantifies the relevance of a word in a document. First, we build the LSA object with the `textmodel_lsa` function from the `quanteda.textmodels` package with our matrix created for the TF-IDF grouped model reviews(*only 5 dimensions*). Next, we break down the data for interpretability by considering only the 5 words with the highest values and the 5 with the lowest values. Finally, we plot the Biplot to identify the Topics and its words associated and unrelated.

What we discover is that Topic 2 (*Dim 2*) is associated to the words "scratch", "iphone", "generic", "health", "renew" and the models iPhone 11 Pro, iPhone 11, iPhone 11 Pro Max. Thereby, is unrelated to terms such as "s21", "s8", "samsung", "s20", "fe" and the model Samsung Galaxy S21 FE. For Topic 3 (*Dim 3*) we see a relation with terms like "aesthetic", "mica", "generic", "pro", "max" and iPhone 11 Pro, iPhone 11 Pro Max, but unrelated to iPhone 11 and the words "transfer", "red", "yellow", "purple", "daughter".

Comparing both (*DFM and TF-IDF*) LSA approaches, we identify that for Topic 2 the words that are similar are "scratch" and "iphone". This make sense, as we have seen that the main concern from iPhone reviewers is comparing their new model with previous models (*usage of term iphone*) or praising/complaining about the current status of the smartphone received (*usage of term scratch*). For Topic 3, we detect that terms changed significantly, meaning that the context of the topic would be different, with the exception of the word **Pro**.

```{r, warning=FALSE}
Smartphone_reviews.lsa2 <- textmodel_lsa(Smartphone_reviews.tfidf.group, 
                                         nd = 5) 

n.terms <- 5
w.order <- sort(Smartphone_reviews.lsa2$features[,2], decreasing = TRUE)
w.top2 <- c(w.order[1:n.terms], rev(rev(w.order)[1:n.terms]))

w.order <- sort(Smartphone_reviews.lsa2$features[,3], decreasing = TRUE)
w.top3 <- c(w.order[1:n.terms], rev(rev(w.order)[1:n.terms]))

w.subset <- Smartphone_reviews.lsa2$features[c(unique(c(names(w.top2), names(w.top3)))),2:3]
biplot(
  y = Smartphone_reviews.lsa2$docs[,2:3],
  x = w.subset,
  col = c("black", "red"),
  cex = c(0.8, 0.8),
  xlab = "Dim 2",
  ylab="Dim 3")
```

### **LDA**

Latent Dirichlet Allocation (LDA) is a topic modeling algorithm that is used to identify the topics present in a collection of documents. It is a generative model that assumes that each document is a mixture of a fixed number of topics, and that each word in the document is associated with one of the topics (*Susan Li, 2018*).

We decided to incorporate this algorithm to our dataset, so we build the LDA object with the `textmodel_lda` function from the `seededlda` package. We wanted to apply the same amount of topics (*5 topics*) similar than the LSA DTM approach because we tried with 10, 9, and 7 topics but the results were not meaningful.

Below we can observe the top 5 terms appearing on each topic

```{r}
# Term-Topic Analysis
set.seed(123)
Smartphone_reviews.lda <- textmodel_lda(x = Smartphone_reviews.dfm.group, k = 5)
seededlda::terms(Smartphone_reviews.lda, 5) %>% 
  kable(caption = "Top 5 terms per Topic") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) 
```

#### **Term-Topic Analysis**

The $Ï•$ (phi) is a term-topic distribution. It represents the probability of a term occurring in a given topic. To rephrase it, for a given topic, the $Ï•$ values indicate the likelihood of each term being associated with that topic. The terms with the highest $Ï•$ values are the ones that are most strongly associated with the topic. To visualize those associations we plot the $Ï•$ values with the 10 largest probabilities terms inside each subject.

So we can interpret the following:

-   Topic 1: The reviews found with this topic will talk more about the color of the models, the capacity, and size.
-   Topic 2: It is mainly related to the term phone, so we expect that this topic will be among all models (*Topic-Document Analysis*).
-   Topic 3: Refers to more to the characteristics and conditions of the smartphones.
-   Topic 4: We can assume that this topic will be associated with some of the iPhone models, as we see the terms "pro" and "max" on the top 3, and maybe some samsung models, due to the words "aesthetic", detail.
-   Topic 5: The top terms tell us that this topic is oriented to the brand Samsung, as we can identify the main terms are related to Samsung models.

```{r}
# Term-Topic Analysis
phi.long <- melt(
  Smartphone_reviews.lda$phi,
  varnames = c("Topic", "Term"),
  value.name = "Phi") 

phi.long %>% 
  group_by(Topic) %>% 
  top_n(10, Phi) %>% 
  ggplot(aes(reorder_within(Term, Phi, Topic), Phi, fill=Topic)) + 
  geom_col(show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~ Topic, scales = "free_y") +
  scale_x_reordered() + 
  xlab("Term") + 
  theme(
    axis.text.y = element_text(size = 8),
    strip.text = element_text(size = 8))

```

#### **Topic-Document Analysis**

The Î¸ matrix (theta) is a document-topic distribution. It represents the probability of a topic occurring in a given document. To put it in another way, for a given document, the Î¸ values indicate the likelihood of each topic being present in that document.

Looking at the below chart, we can identify the following:

-   The models reviews from the first row, the iPhone 13 mini, iPhone 13 Pro, and iPhone 13 Pro Max mostly talk 50% about Topic 3.
-   Unsurprisingly we see that all models have a significant percentage that is about Topic 2.
-   On Samsung models its observed that Topic 4 had a minor appearance. However, for Apple models we see a higher participation.
-   Topic 5 is mainly observed in all Samsung models. Meaning that what we believed on the previous analysis is correct.
-   About Topic 1 is slightly prevalent on the mini models of Apple, the Iphone 13, and the Samsung models S20 Plus and FE.

```{r}
# Topic-Document Analysis
set.seed(123)
theta.long <- melt(
  Smartphone_reviews.lda$theta,
  varnames = c("Doc", "Topic"),
  value.name = "Theta")

ggplot(theta.long,
       aes(x = Theta,
           y = Doc,
           fill = Topic)) + 
  geom_bar(stat="identity") +
  ylab("Models") 

# # Other graphical representation
# theta.long %>% 
#   filter(Doc %in% doc.list) %>%  
#   ggplot(aes(reorder_within(Topic, Theta, Doc), Theta, fill=Topic)) + 
#   geom_col(show.legend = FALSE) +
#   coord_flip()+
#   facet_wrap(~ Doc, scales = "free_y") +
#   scale_x_reordered() + 
#   xlab("Models") +
#    theme(
#     axis.text.y = element_text(size = 8),
#     strip.text = element_text(size = 8))
```

#### **LDA Diagnostics across Topics - *Prevalence, Coherence and Exclusivity* -**

There are several ways to evaluate the quality of a topic model, for this case, we have consider to evaluate the LDA using metrics such as prevalence, coherence, and exclusivity.

Prevalence is a measure of how frequently a topic appears in the documents. A topic with a high prevalence is likely to be important and relevant to the overall collection of documents, while a topic with a low prevalence may not be as important or relevant.

Coherence is a measure of how well the words within a topic are related to each other. A topic with high coherence is likely to be more interpretable and easier to understand, while a topic with low coherence may be more difficult to interpret.

Exclusivity is a measure of how unique a topic is compared to the other topics in the model. A topic with high exclusivity is likely to be more distinct and easily separable from other topics, while a topic with low exclusivity may overlap with other topics and be harder to distinguish.

On the top left-hand side of the chart below, we can observe that the most prevalent topic among the models is Topic 2, this makes sense, as we have seen on the previous chart that this topic was a the most common. Additionally, we detect that Topic 2 is also the most coherent, whereas the least coherent is Topic 1. But we can note that Topic 1 is the most exclusive because its five terms are more specific to it.

```{r}
# Most Prevalent Topic
prevalence.topic <- rev(sort(colSums(Smartphone_reviews.lda$theta)/sum(Smartphone_reviews.lda$theta))) %>% 
  data.frame()
prevalence.topic$Topic <- rownames(prevalence.topic)
prevalence.topic <- data.frame(prevalence.topic) %>% 
  rename("Prevalence" = ".")

# Plot the Prevalence
p5 <- ggplot(prevalence.topic,
       aes(x = Topic,
           y = Prevalence,
           fill = Topic)) + 
  geom_bar(stat="identity") +
  ylab("Prevalence") 

# Topic Coherence
speech.codo <- fcm(
  Smartphone_reviews.dfm.group, 
  context = "document",
  count = "boolean",
  tri = FALSE) # co-document frequencies
term.mat <- seededlda::terms(Smartphone_reviews.lda, 5)
Coh <- rep(0, 5)
names(Coh) <- paste0("Topic", 1:5)
for (k in 1:5) {
  D.mat <- t(speech.codo[term.mat[,k], term.mat[,k]])
  D.vec <- Smartphone_reviews.dfm.group %>% 
    textstat_frequency %>% 
    filter(feature %in% term.mat[, k]) %>% 
    data.frame %>%
    select(feature, docfreq)
  for (m in 2:5){
    for (l in 1:(m - 1)) {
      vm <- term.mat[m, k]
      vl <- term.mat[l, k]
      Coh[k] <- Coh[k] + log((D.mat[vm, vl] + 1) / filter(D.vec, feature == vl)$docfreq)
    }
  }
}
coherence.topic <- rev(sort(Coh)) %>% 
  data.frame()
coherence.topic$Topic <- rownames(coherence.topic)
coherence.topic <- data.frame(coherence.topic) %>% 
  rename("Coherence" = ".")

# Plot the Coherence
p6 <- ggplot(coherence.topic,
       aes(x = Topic,
           y = Coherence,
           fill = Topic)) + 
  geom_bar(stat="identity") +
  ylab("Coherence") +
  coord_flip()

# Exclusivity of the topic
excl <- rep(0, 5)
names(excl) <- paste0("Topic", 1:5)
for (k in 1:5) {
  for (i in 1:length(term.mat[,k])) {
    term.phi <- filter(phi.long, Term == term.mat[i,k])
    excl[k] <- excl[k] + filter(term.phi, Topic == "topic1")$Phi / sum(term.phi$Phi)
  }
  excl[k] <- excl[k] / length(term.mat[, k])
}

exclusivity.topic <- rev(sort(excl)) %>% 
  data.frame()
exclusivity.topic$Topic <- rownames(exclusivity.topic)
exclusivity.topic <- data.frame(exclusivity.topic) %>% 
  rename("Exclusivity" = ".")

# Plot the Exclusivity
p7 <- ggplot(exclusivity.topic,
       aes(x = Topic,
           y = Exclusivity,
           fill = Topic)) + 
  geom_bar(stat="identity") +
  ylab("Exclusivity") 

(p5|p7) / p6
```
